{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#import row data\n",
    "row_data = np.loadtxt('sarcos_inv.csv',delimiter = ',')\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(row_data)\n",
    "X = row_data[:,:21]\n",
    "Y = row_data[:,21:]\n",
    "\n",
    "# normalize_x\n",
    "X = (X - np.mean(X)) / np.std(X)\n",
    "\n",
    "#split data\n",
    "split_size = [0.6,0.2,0.2]\n",
    "index_train = int(X.shape[0] * split_size[0])\n",
    "index_cv = index_train + int(X.shape[0] * split_size[1])\n",
    "index_test = index_cv + int(X.shape[0] * split_size[2])\n",
    "X_train = X[:index_train, :]\n",
    "Y_train = Y[:index_train, :]\n",
    "X_test = X[index_cv:index_test, :]\n",
    "Y_test = Y[index_cv:index_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(X, Y, nodes):\n",
    "    if len(X) <= nodes:\n",
    "        is_leaf=True\n",
    "        mean=np.mean(Y)\n",
    "        std=np.std(Y)\n",
    "        feature=None\n",
    "        best_split=None\n",
    "        left=None\n",
    "        right=None\n",
    "#     feature, best_split, left_indices, right_indices = DecisionTree._best_split_random(X, Y)\n",
    "    min_sse = np.inf\n",
    "    random_feature_indices_ = np.random.choice(np.arange(X.shape[1]), size=int(X.shape[1] // 2 + 1), replace=False)\n",
    "    for j in range(len(random_feature_indices_)):\n",
    "        i = random_feature_indices_[j]\n",
    "        num_values = X[:, i].shape[0]\n",
    "        random_values_indices = np.random.choice(np.arange(num_values), size=int(2 * np.sqrt(num_values)), replace=False)\n",
    "        values = X[random_values_indices, i]\n",
    "        for split in values:\n",
    "            left_indices = X[:, i:(i+1)] <= split\n",
    "            left_indices, _ = np.nonzero(left_indices)\n",
    "            right_indices = X[:, i:(i+1)] > split\n",
    "            right_indices, _ = np.nonzero(right_indices)\n",
    "#         sse = DecisionTree._sum_of_squared_errors(Y[left_indices], Y[right_indices])\n",
    "            if len(Y[left_indices]) == 0:\n",
    "                sse1 = 0\n",
    "            else:\n",
    "                sse1 = np.sum((Y[left_indices] - np.mean(Y[left_indices]))**2)\n",
    "            if len(Y[right_indices]) == 0:\n",
    "                sse2 = 0\n",
    "            else:\n",
    "                sse2 = np.sum((Y[right_indices] - np.mean(Y[right_indices])) ** 2)\n",
    "            sse = sse1 + sse2\n",
    "            if sse < min_sse:\n",
    "                feature = i\n",
    "                best_split = split\n",
    "                left = left_indices\n",
    "                right = right_indices\n",
    "                min_sse = sse\n",
    "    feature = feature\n",
    "    best_split = best_split\n",
    "    left_indices = left\n",
    "    right_indices = right\n",
    "    left = create_tree(X[left_indices], Y[left_indices], min_nodes)\n",
    "    right = create_tree(X[right_indices], Y[right_indices], min_nodes)\n",
    "#     return Node(is_leaf=False, mean=np.mean(Y), std=np.std(Y), feature=feature, split=best_split, left=left, right=right)\n",
    "    is_leaf = False\n",
    "    mean  = np.mean(Y)\n",
    "    std = np.std(Y)\n",
    "    feature = feature\n",
    "    split = best_split\n",
    "    left = left\n",
    "    right = right\n",
    "    return is_leaf, mean, std, feature, split, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict(node, x):\n",
    "    \"\"\"\n",
    "    Helper function for the predict function.\n",
    "    :param node: Current node in the tree\n",
    "    :param x: Input vector for which we predict the output value\n",
    "    :return: Mean of the leaf node, standard deviation of the leaf node\n",
    "    \"\"\"\n",
    "    if node.is_leaf:\n",
    "        return node.mean, node.std\n",
    "    if x[node.feature] <= node.split:\n",
    "        return _predict(node.left, x)\n",
    "    else:\n",
    "        return _predict(node.right, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_num=50\n",
    "train_size=4000\n",
    "nodes=5\n",
    "trees = []\n",
    "for i in range(tree_num):\n",
    "    a = np.random.choice(np.arange(X_train.shape[0]), size=train_size, replace=False)\n",
    "    X = X_train[a]\n",
    "    Y = Y_train[a]\n",
    "#     tree = DecisionTree(X_train[a], Y_train[a], nodes)\n",
    "    root = create_tree(X_train[a], Y_train[a], nodes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    \n",
    "    means = np.zeros((X_test.shape[0], 1))\n",
    "    stds = np.zeros((X_test.shape[0], 1))\n",
    "    for i in range(X_test.shape[0]):\n",
    "        mean_all = 0\n",
    "        std_all = 0\n",
    "        for tree in trees:\n",
    "            mean, std = tree.predict(X_test[i])\n",
    "            mean_all = mean_all + mean\n",
    "            std_all = std_all + std\n",
    "        means[i] = mean_all / len(trees)\n",
    "        stds[i] = std_all / len(trees)\n",
    "        \n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarcos_regression_forest():\n",
    "    X_train, Y_train, X_cv, Y_cv, X_test, Y_test = data.get_data_split([0.6, 0.2, 0.2], normalize=False)\n",
    "    print('Regression forests, sarcos:')\n",
    "    print('\\tThis will take about 6 minutes, please wait...')\n",
    "    model = RandomForest(X_train, Y_train, num_trees=30, training_set_size=4000, min_nodes=5)\n",
    "    mean, std = model.predict_all(X_test)\n",
    "    rmse = np.sqrt(np.mean(np.square(mean - Y_test)))\n",
    "    print('\\tRMSE: ' + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree:\n",
    "    def def __init__(self, X_train, Y_train, min_nodes):\n",
    "        self.root = self._create_tree(X_train, Y_train, min_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tree(X, Y, nodes):\n",
    "    if len(X) <= nodes:\n",
    "        is_leaf = True\n",
    "        mean = np.mean(Y)\n",
    "        std = np.std(Y)\n",
    "        feature=None\n",
    "        best_split=None\n",
    "        left=None\n",
    "        right=None  \n",
    "#     feature, best_split, left_indices, right_indices = DecisionTree._best_split_random(X, Y)\n",
    "    min_sse = 10000000000000000\n",
    "    feature = None\n",
    "    best_split = None\n",
    "    left = None\n",
    "    right = None\n",
    "    random_feature_indices_ = np.random.choice(np.arange(X.shape[1]), size=int(X.shape[1] // 2 + 1), replace=False)\n",
    "    for j in range(len(random_feature_indices_)):\n",
    "        i = random_feature_indices_[j]\n",
    "        num_values = X[:, i].shape[0]\n",
    "        random_values_indices = np.random.choice(np.arange(num_values), size=int(2 * np.sqrt(num_values)))\n",
    "        values = X[random_values_indices, i]\n",
    "        for split in values:\n",
    "            left_indices = X[:, i:(i+1)] <= split\n",
    "            left_indices, _ = np.nonzero(left_indices)\n",
    "            right_indices = X[:, i:(i+1)] > split\n",
    "            right_indices, _ = np.nonzero(right_indices)\n",
    "            if len(Y[left_indices]) == 0:\n",
    "                sse1 = 0\n",
    "            else:\n",
    "                sse1 = np.sum((Y[left_indices] - np.mean(Y[left_indices]))**2)\n",
    "            if len(Y[right_indices]) == 0:\n",
    "                sse2 = 0\n",
    "            else:\n",
    "                sse2 = np.sum((Y[right_indices] - np.mean(Y[right_indices])) ** 2)\n",
    "            sse = sse1 + sse2\n",
    "#             sse = DecisionTree._sum_of_squared_errors(Y[left_indices], Y[right_indices])\n",
    "            if sse < min_sse:\n",
    "                feature = i\n",
    "                best_split = split\n",
    "                left = left_indices\n",
    "                right = right_indices\n",
    "                min_sse = sse\n",
    "    left_indices = left\n",
    "    right_indices = right\n",
    "    \n",
    "    left = create_tree(X[left_indices], Y[left_indices], nodes)\n",
    "    right = create_tree(X[right_indices], Y[right_indices], nodes)\n",
    "    is_leaf=False\n",
    "    mean=np.mean(Y)\n",
    "    std=np.std(Y)\n",
    "    feature=feature\n",
    "    split=best_split\n",
    "    left=left\n",
    "    right=right\n",
    "    return is_leaf, mean, std, feature, split, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_num=50\n",
    "train_size=4000\n",
    "nodes=5\n",
    "trees = []\n",
    "for i in range(tree_num):\n",
    "    a = np.random.choice(np.arange(X_train.shape[0]), size=train_size, replace=False)\n",
    "    X = X_train[a]\n",
    "    Y = Y_train[a]\n",
    "#     tree = DecisionTree(X = X_train[a], Y = Y_train[a], nodes)\n",
    "#     self.root = self._create_tree(X_train[a], Y_train[a], nodes)\n",
    "    if len(X_train[a]) <= nodes:\n",
    "#     return Node(is_leaf=True, mean=np.mean(Y_train[a]), std=np.std(Y_train[a]), feature=None, split=None, left=None, right=None)\n",
    "        is_leaf = True\n",
    "        mean = np.mean(Y_train[a])\n",
    "        std = np.std(Y_train[a])\n",
    "        feature=None\n",
    "        best_split=None\n",
    "        left=None\n",
    "        right=None  \n",
    "    \n",
    "#     feature, best_split, left_indices, right_indices = DecisionTree._best_split_random(X, Y)\n",
    "    m = 1000000000\n",
    "    b= np.random.choice(np.arange(X.shape[1]), size=int(X.shape[1] // 2 + 1), replace=False)\n",
    "    for j in range(len(b)):\n",
    "        i = b[j]\n",
    "        k = X[:, i].shape[0]\n",
    "        c = np.random.choice(np.arange(k), size=int(2 * np.sqrt(k)), replace=False)\n",
    "        k_v = X[c, i]\n",
    "        for w in k_v:\n",
    "            left_indices = X[:, i:(i+1)] <= w\n",
    "            left_indices, _ = np.nonzero(left_indices)\n",
    "            right_indices = X[:, i:(i+1)] > w\n",
    "            right_indices, _ = np.nonzero(right_indices)\n",
    "#             sse = DecisionTree._sum_of_squared_errors(Y[left_indices], Y[right_indices])\n",
    "            if len(Y[left_indices]) == 0:\n",
    "                sse1 = 0\n",
    "            else:\n",
    "                sse1 = np.sum((Y[left_indices] - np.mean(Y[left_indices]))**2)\n",
    "            if len(Y[right_indices]) == 0:\n",
    "                sse2 = 0\n",
    "            else:\n",
    "                sse2 = np.sum((Y[right_indices] - np.mean(Y[right_indices])) ** 2)\n",
    "            sse = sse1 + sse2\n",
    "            if sse < m:\n",
    "                feature = i\n",
    "                best_split = w\n",
    "                left = left_indices\n",
    "                right = right_indices\n",
    "                m = sse    \n",
    "   \n",
    "#     left = self._create_tree(X[left_indices], Y[left_indices], min_nodes))\n",
    "    if len(X[left_indices]) <= nodes:\n",
    "    return Node(is_leaf=True, mean=np.mean(Y), std=np.std(Y), feature=None, split=None, left=None, right=None)\n",
    "\n",
    "    right = self._create_tree(X[right_indices], Y[right_indices], min_nodes)\n",
    "    return Node(is_leaf=False, mean=np.mean(Y), std=np.std(Y), feature=feature, split=best_split, left=left, right=right)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.root = self._create_tree(X_train, Y_train, min_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
