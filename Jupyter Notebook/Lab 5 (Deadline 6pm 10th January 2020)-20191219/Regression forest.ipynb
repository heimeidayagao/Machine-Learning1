{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sarcos_inv.csv\",header = None)\n",
    "\n",
    "def splitData(data,seed,m,k):\n",
    "#将数据分成训练集和测试集，每次指定seed，更换K,重复M次,防止过拟合.\n",
    "    test=[]\n",
    "    train=[]\n",
    "    #random.seed(seed),指定seed的话，每次后面的随机数产生的都是一样的顺序\n",
    "    np.random.seed(seed)\n",
    "    for index, row in data.iterrows():\n",
    "        #随机数产生顺序一样,随机产生（0，m）之间的数，只有一个可以分给测试集，另外的m-1都分给训练集\n",
    "        if np.random.randint(0,m)==k:\n",
    "            test.append([index,row])\n",
    "        else:\n",
    "            train.append([index,row])\n",
    "    return test,train\n",
    "test,train=splitData(data,5,6,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_training(data_train, trees_num):\n",
    "    '''构建随机森林\n",
    "    input:  data_train(list):训练数据\n",
    "            trees_num(int):分类树的个数\n",
    "    output: trees_result(list):每一棵树的最好划分\n",
    "            trees_feature(list):每一棵树中对原始特征的选择\n",
    "    '''\n",
    "    trees_result = []  # 构建好每一棵树的最好划分\n",
    "    trees_feature = []\n",
    "    n = np.shape(data_train)[1]  # 样本的维数\n",
    "    if n > 2:\n",
    "        k = int(log(n - 1, 2)) + 1 # 设置特征的个数\n",
    "    else:\n",
    "        k = 1\n",
    "    # 开始构建每一棵树\n",
    "    for i in range(trees_num):\n",
    "        # 1、随机选择m个样本, k个特征\n",
    "        data_samples, feature = choose_samples(data_train, k)\n",
    "        # 2、构建每一棵分类树\n",
    "        tree = build_tree(data_samples)\n",
    "        # 3、保存训练好的分类树\n",
    "        trees_result.append(tree)\n",
    "        # 4、保存好该分类树使用到的特征\n",
    "        trees_feature.append(feature)\n",
    "   \n",
    "    return trees_result, trees_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_samples(data, k):\n",
    "    '''\n",
    "    input:  data(list):原始数据集\n",
    "            k(int):选择特征的个数\n",
    "    output: data_samples(list):被选择出来的样本\n",
    "            feature(list):被选择的特征index\n",
    "    '''\n",
    "    m, n = np.shape(data)  # 样本的个数和样本特征的个数\n",
    "    # 1、选择出k个特征的index\n",
    "    feature = []\n",
    "    for j in range(k):\n",
    "        feature.append(rd.randint(0, n - 2))  # n-1列是标签\n",
    "    # 2、选择出m个样本的index\n",
    "    index = []\n",
    "    for i in range(m):\n",
    "        index.append(rd.randint(0, m - 1))\n",
    "    # 3、从data中选择出m个样本的k个特征，组成数据集data_samples\n",
    "    data_samples = []\n",
    "    for i in range(m):\n",
    "        data_tmp = []\n",
    "        for fea in feature:\n",
    "            data_tmp.append(data[index[i]][fea])\n",
    "        data_tmp.append(data[index[i]][-1])\n",
    "        data_samples.append(data_tmp)\n",
    "    return data_samples, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data):\n",
    "    '''构建树\n",
    "    input:  data(list):训练样本\n",
    "    output: node:树的根结点\n",
    "    '''\n",
    "    # 构建决策树，函数返回该决策树的根节点\n",
    "    if len(data) == 0:\n",
    "        return node()\n",
    "   \n",
    "    # 1、计算当前的Gini指数\n",
    "    currentGini = cal_gini_index(data)\n",
    "   \n",
    "    bestGain = 0.0\n",
    "    bestCriteria = None  # 存储最佳切分属性以及最佳切分点\n",
    "    bestSets = None  # 存储切分后的两个数据集\n",
    "   \n",
    "    feature_num = len(data[0]) - 1  # 样本中特征的个数\n",
    "    # 2、找到最好的划分\n",
    "    for fea in range(0, feature_num):\n",
    "        # 2.1、取得fea特征处所有可能的取值\n",
    "        feature_values = {}  # 在fea位置处可能的取值\n",
    "        for sample in data:  # 对每一个样本\n",
    "            feature_values[sample[fea]] = 1  # 存储特征fea处所有可能的取值\n",
    "       \n",
    "        # 2.2、针对每一个可能的取值，尝试将数据集划分，并计算Gini指数\n",
    "        for value in feature_values.keys():  # 遍历该属性的所有切分点\n",
    "            # 2.2.1、 根据fea特征中的值value将数据集划分成左右子树\n",
    "            (set_1, set_2) = split_tree(data, fea, value)\n",
    "            # 2.2.2、计算当前的Gini指数\n",
    "            nowGini = float(len(set_1) * cal_gini_index(set_1) + \n",
    "                             len(set_2) * cal_gini_index(set_2)) / len(data)\n",
    "            # 2.2.3、计算Gini指数的增加量\n",
    "            gain = currentGini - nowGini\n",
    "            # 2.2.4、判断此划分是否比当前的划分更好\n",
    "            if gain > bestGain and len(set_1) > 0 and len(set_2) > 0:\n",
    "                bestGain = gain\n",
    "                bestCriteria = (fea, value)\n",
    "                bestSets = (set_1, set_2)\n",
    "   \n",
    "    # 3、判断划分是否结束\n",
    "    if bestGain > 0:\n",
    "        right = build_tree(bestSets[0])\n",
    "        left = build_tree(bestSets[1])\n",
    "        return node(fea=bestCriteria[0], value=bestCriteria[1], \n",
    "                    right=right, left=left)\n",
    "    else:\n",
    "        return node(results=label_uniq_cnt(data))  # 返回当前的类别标签作为最终的类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cal_gini_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-819f07c0d7e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrees_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrees_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_forest_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-6cea91999aa0>\u001b[0m in \u001b[0;36mrandom_forest_training\u001b[1;34m(data_train, trees_num)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdata_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# 2、构建每一棵分类树\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m# 3、保存训练好的分类树\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mtrees_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-e3a192a9b709>\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# 1、计算当前的Gini指数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mcurrentGini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_gini_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mbestGain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cal_gini_index' is not defined"
     ]
    }
   ],
   "source": [
    "trees_result, trees_feature = random_forest_training(train, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
