{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        :param X_train: training set\n",
    "        :param Y_train: outputs of the training set\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        n = self.X_train.shape[1]\n",
    "        self.w = np.random.normal(0, 0.5, size=(n, 1))\n",
    "        self.b = np.random.normal(0, 0.5)\n",
    "\n",
    "    def train(self, iterations, learning_rate, print_iterations=False):\n",
    "        \"\"\"\n",
    "        Optimizes the objective function with the gradient descent algorithm\n",
    "        in order to find well suited parameters w and b.\n",
    "        :param iterations: The number of gradient descent iterations\n",
    "        :param learning_rate: Step size of the gradient descent algorithm\n",
    "        :param print_iterations: Whether or not the current iteration and its training loss shall be printed to console\n",
    "        \"\"\"\n",
    "        cost_prev = np.inf\n",
    "        current_learning_rate = learning_rate\n",
    "        for _ in range(iterations):\n",
    "            prediction = np.dot(self.X_train, self.w) + self.b\n",
    "            cost = self._cost(prediction)\n",
    "            if print_iterations:\n",
    "                print('Iteration ' + str(_) + ', cost: ' + str(cost))\n",
    "            self._update_weights(learning_rate, prediction)\n",
    "\n",
    "            if cost >= cost_prev:\n",
    "                current_learning_rate = current_learning_rate * 0.5\n",
    "                continue\n",
    "\n",
    "            if np.fabs(cost - cost_prev) < 1e-12:\n",
    "                print('Stopping early')\n",
    "                break\n",
    "\n",
    "            cost_prev = cost\n",
    "\n",
    "    def test(self, X_test, Y_test):\n",
    "        \"\"\"\n",
    "        Test the current parameters on the provided test set.\n",
    "        :param X_test: Test set\n",
    "        :param Y_test: Output values for the test set\n",
    "        :return: RMSE for the test set, predictions on the test set\n",
    "        \"\"\"\n",
    "        prediction = np.dot(X_test, self.w) + self.b\n",
    "        rmse = np.sqrt(np.mean(np.square(prediction - Y_test)))\n",
    "        return rmse, prediction\n",
    "\n",
    "    def _update_weights(self, learning_rate, prediction):\n",
    "        \"\"\"\n",
    "        Implements the parameter update in the direction of the negative\n",
    "        gradient of the objective function.\n",
    "        :param learning_rate: The step size\n",
    "        :param prediction: The predictions from the current iteration\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grad_w, grad_b = self._compute_gradient(prediction)\n",
    "        self.w = self.w - learning_rate * grad_w\n",
    "        self.b = self.b - learning_rate * grad_b\n",
    "\n",
    "    def _compute_gradient(self, prediction):\n",
    "        \"\"\"\n",
    "        Computes the gradient for the parameters w and b.\n",
    "        :param prediction: The predictions from the current iteration\n",
    "        :return: gradient of w, gradient of b\n",
    "        \"\"\"\n",
    "        m = prediction.shape[0]\n",
    "        grad_w = np.dot(self.X_train.T, (prediction - self.Y_train)) / m\n",
    "        grad_b = np.sum((prediction - self.Y_train)) / m\n",
    "        return grad_w, grad_b\n",
    "\n",
    "    def _cost(self, prediction):\n",
    "        \"\"\"\n",
    "        Computes the cost for the current set of parameters.\n",
    "        :param prediction: The predictions from the current iteration\n",
    "        :return: Cost value\n",
    "        \"\"\"\n",
    "        return np.sum((prediction - self.Y_train)**2) / (2 * self.Y_train.shape[0])\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Resets the parameters of the model.\n",
    "        \"\"\"\n",
    "        n = self.X_train.shape[1]\n",
    "        self.w = np.random.normal(0, 0.5, size=(n, 1))\n",
    "        self.b = np.random.normal(0, 0.5)\n",
    "\n",
    "    def normal_equation(self, X_test, Y_test):\n",
    "        \"\"\"\n",
    "        Computes the exact solution for the linear regression problem via the normal equation.\n",
    "        :param X_test: Test set\n",
    "        :param Y_test: Output values of the test set\n",
    "        :return: RMSE of the test set, predictions for the test set\n",
    "        \"\"\"\n",
    "        X = np.copy(self.X_train)\n",
    "        X = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        w = np.dot(np.dot(np.dot(X.T, X), X.T), self.Y_train)\n",
    "        X_ = np.copy(X_test)\n",
    "        X_ = np.append(np.ones((X_.shape[0],1)), X_, axis=1)\n",
    "        print(w.shape)\n",
    "        print(X_.shape)\n",
    "        prediction = np.dot(X_, w)\n",
    "        rmse = np.sqrt(np.mean(np.square(prediction - Y_test)))\n",
    "        return rmse, prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
